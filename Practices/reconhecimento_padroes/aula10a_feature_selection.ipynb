{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fboldt/aulasml/blob/master/aula10a_feature_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".. _covtype_dataset:\n",
            "\n",
            "Forest covertypes\n",
            "-----------------\n",
            "\n",
            "The samples in this dataset correspond to 30×30m patches of forest in the US,\n",
            "collected for the task of predicting each patch's cover type,\n",
            "i.e. the dominant species of tree.\n",
            "There are seven covertypes, making this a multiclass classification problem.\n",
            "Each sample has 54 features, described on the\n",
            "`dataset's homepage <https://archive.ics.uci.edu/ml/datasets/Covertype>`__.\n",
            "Some of the features are boolean indicators,\n",
            "while others are discrete or continuous measurements.\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    =================   ============\n",
            "    Classes                        7\n",
            "    Samples total             581012\n",
            "    Dimensionality                54\n",
            "    Features                     int\n",
            "    =================   ============\n",
            "\n",
            ":func:`sklearn.datasets.fetch_covtype` will load the covertype dataset;\n",
            "it returns a dictionary-like 'Bunch' object\n",
            "with the feature matrix in the ``data`` member\n",
            "and the target values in ``target``. If optional argument 'as_frame' is\n",
            "set to 'True', it will return ``data`` and ``target`` as pandas\n",
            "data frame, and there will be an additional member ``frame`` as well.\n",
            "The dataset will be downloaded from the web if necessary.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "\n",
        "covtype = fetch_covtype()\n",
        "description = covtype.DESCR\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((581012, 54), (581012,))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, y = fetch_covtype(return_X_y=True, shuffle=True)\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Referências: \n",
        "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
        "https://sherbold.github.io/intro-to-data-science/exercises/Solution_Classification.html\n",
        "https://www.kaggle.com/code/maostack/classifiers-tips/notebook#Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    KNeighborsClassifier(5),\n",
        "    KNeighborsClassifier(10),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    DecisionTreeClassifier(max_depth=10),\n",
        "    DecisionTreeClassifier(max_depth=20),\n",
        "    RandomForestClassifier(n_estimators=1000, max_depth=3, n_jobs=-1),\n",
        "    RandomForestClassifier(n_estimators=1000, max_depth=5, n_jobs=-1),\n",
        "    LogisticRegression(max_iter=10000, solver='lbfgs', n_jobs=-1),\n",
        "    SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=1000, n_jobs=-1),\n",
        "    GaussianNB(),\n",
        "    MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=10000, activation='relu'),\n",
        "    MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=10000, activation='tanh')\n",
        "]\n",
        "\n",
        "clf_names = [\n",
        "    \"Nearest Neighbors (k=3)\",\n",
        "    \"Nearest Neighbors (k=5)\",\n",
        "    \"Nearest Neighbors (k=10)\",\n",
        "    \"Decision Tree (Max Depth=5)\",\n",
        "    \"Decision Tree (Max Depth=10)\",\n",
        "    \"Decision Tree (Max Depth=20)\",\n",
        "    \"Random Forest (Max Depth=3)\",\n",
        "    \"Random Forest (Max Depth=5)\",\n",
        "    \"Logistic Regression\",\n",
        "    \"SGD Classifier\",\n",
        "    \"Gaussian Naive Bayes\",\n",
        "    \"MLP (RelU)\",\n",
        "    \"MLP (tanh)\"\n",
        "]çç\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classificador: Nearest Neighbors (k=3)\n",
            "Scores: [0.93255768 0.93291912 0.93243662 0.93471713 0.93378771]\n",
            "Média das pontuações de validação cruzada: 0.9332836517843155\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Classificador: Nearest Neighbors (k=5)\n",
            "Scores: [0.92811717 0.92814299 0.92869314 0.92996678 0.929089  ]\n",
            "Média das pontuações de validação cruzada: 0.928801817076874\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Classificador: Nearest Neighbors (k=10)\n",
            "Scores: [0.91659424 0.91705894 0.91695496 0.91765202 0.91778111]\n",
            "Média das pontuações de validação cruzada: 0.9172082517457945\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Classificador: Decision Tree (Max Depth=5)\n",
            "Scores: [0.70310577 0.70004217 0.69991911 0.70593449 0.70223404]\n",
            "Média das pontuações de validação cruzada: 0.7022471159740118\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Classificador: Decision Tree (Max Depth=10)\n",
            "Scores: [0.77782846 0.77639992 0.77390234 0.7795649  0.77773188]\n",
            "Média das pontuações de validação cruzada: 0.7770854989959274\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Classificador: Decision Tree (Max Depth=20)\n",
            "Scores: [0.90632772 0.90557042 0.9090205  0.90757474 0.90581057]\n",
            "Média das pontuações de validação cruzada: 0.9068607908673796\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Classificador: Random Forest (Max Depth=3)\n",
            "Scores: [0.66199668 0.65916543 0.65786303 0.662949   0.66190771]\n",
            "Média das pontuações de validação cruzada: 0.6607763701793354\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Classificador: Random Forest (Max Depth=5)\n",
            "Scores: [0.68086882 0.67830435 0.67769918 0.68435999 0.67957522]\n",
            "Média das pontuações de validação cruzada: 0.6801615132731432\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Classificador: Logistic Regression\n",
            "Scores: [0.72535132 0.72275242 0.72394623 0.72713034 0.72500473]\n",
            "Média das pontuações de validação cruzada: 0.7248370112325959\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Classificador: SGD Classifier\n",
            "Scores: [0.71427588 0.70869083 0.71164008 0.71239738 0.70725977]\n",
            "Média das pontuações de validação cruzada: 0.7108527857236453\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Classificador: Gaussian Naive Bayes\n",
            "Scores: [0.08764834 0.08799256 0.08929278 0.08760607 0.0870553 ]\n",
            "Média das pontuações de validação cruzada: 0.08791901061788217\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Classificador: MLP (RelU)\n",
            "Scores: [0.94638693 0.9506295  0.94756545 0.94790107 0.94702329]\n",
            "Média das pontuações de validação cruzada: 0.9479012460776438\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Classificador: MLP (tanh)\n",
            "Scores: [0.95133516 0.95227318 0.95214368 0.9514122  0.9521781 ]\n",
            "Média das pontuações de validação cruzada: 0.9518684642117338\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for clf, clf_name in zip(classifiers, clf_names):\n",
        "    try:\n",
        "        model = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('classifier', clf)\n",
        "        ])\n",
        "        \n",
        "        scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "        mean_score = scores.mean()\n",
        "        \n",
        "        print(f\"Classificador: {clf_name}\")\n",
        "        print(f\"Scores: {scores}\")\n",
        "        print(f\"Média das pontuações de validação cruzada: {mean_score}\")\n",
        "        print('-' * 100)\n",
        "\n",
        "    except Exception as ex:\n",
        "        print(f\"Erro durante a execução do classificador {clf_name}: {str(ex)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPmyy0VNeeh5iLUcBCf2bOR",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
